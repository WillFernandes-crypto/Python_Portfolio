{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import spacy\n",
    "import random\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "from spacy.training import Example\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base = pd.read_csv('data/twitter/Train50.csv', delimiter=';')\n",
    "train_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment', hue='sentiment', data=train_base, palette='viridis', legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base.drop(['id', 'tweet_date', 'query_used'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pd.isnull(train_base));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_base = pd.read_csv('data/twitter/Test.csv', delimiter=';')\n",
    "test_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_base.drop(['id', 'tweet_date', 'query_used'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment', hue='sentiment', data=test_base, palette='viridis', legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pd.isnull(test_base));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = spacy.lang.pt.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove usernames\n",
    "    \n",
    "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text) # remove urls\n",
    "    \n",
    "    text = re.sub(r\" +\", ' ', text) # remove extra spaces\n",
    "    \n",
    "    # Emoticons\n",
    "    emoction_list = {':)': 'emocaopositiva', \n",
    "                     ':-)': 'emocaopositiva', \n",
    "                     ';)': 'emocaopositiva', \n",
    "                     ':(': 'emocaonegativa', \n",
    "                     ':-(': 'emocaonegativa'}\n",
    "    \n",
    "    for emot in emoction_list:\n",
    "        text = text.replace(emot, emoction_list[emot])\n",
    "    \n",
    "    # Lemmatization    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    list = []\n",
    "    for token in doc:\n",
    "        list.append(token.lemma_)\n",
    "        \n",
    "    # Stop words and punctuation\n",
    "    list = [word for word in list if word not in stop_words and word not in string.punctuation]\n",
    "    list = ' '.join([str(element) for element in list if not element.isdigit()])\n",
    "    \n",
    "    return list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing on database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base['tweet_text'] = train_base['tweet_text'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Class treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple_base = [[\"não deixe seus sonhos serem apenas sonhos\", {\"POSITIVO\": True, \"NEGATIVO\": False}],\n",
    "                [\"que tistreza\", {\"POSITIVO\": False, \"NEGATIVO\": True}]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_final = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for text, emotion in zip(train_base['tweet_text'], train_base['sentiment']):\n",
    "    if emotion == 'alegria':\n",
    "        dic = {\"ALEGRIA\": True, \"MEDO\": False}\n",
    "    else:\n",
    "        dic = {\"ALEGRIA\": False, \"MEDO\": True}\n",
    "        \n",
    "    train_base_final.append([text, dic.copy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_base_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spacy.blank('pt')\n",
    "categories = model.add_pipe('textcat')\n",
    "categories.add_label(\"POSITIVO\")\n",
    "categories.add_label(\"NEGATIVO\")\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.begin_training()\n",
    "for epoch in range(1000):\n",
    "    random.shuffle(train_base_final)\n",
    "    losses = {}\n",
    "    for batch in spacy.util.minibatch(train_base_final, size=512):\n",
    "        examples = [Example.from_dict(model.make_doc(text), {'cats': entities}) for text, entities in batch]\n",
    "        model.update(examples, losses=losses)\n",
    "    if epoch % 5 == 0:\n",
    "        print(losses)\n",
    "        history.append(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_loss = []\n",
    "for i in history:\n",
    "    history_loss.append(i.get('textcat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_loss = np.array(history_loss)\n",
    "history_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_loss)\n",
    "plt.title('Progressão do erro')\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('Erro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_disk('data/twitter/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One phrase test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = spacy.load('data/twitter/model')\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Positive Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_text = test_base['tweet_text'][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = loaded_model(positive_text)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_text = \"Deixe que o medo te traga coragem!\"\n",
    "positive_text = preprocessing(positive_text)\n",
    "positive_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Negative text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_text = test_base['tweet_text'][4000]\n",
    "prediction = loaded_model(negative_text)\n",
    "prediction.cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train base evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for text in test_base['tweet_text']:\n",
    "    prediction = loaded_model(text)\n",
    "    predictions.append(prediction.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "for prediction in predictions:\n",
    "    if prediction['POSITIVO'] > prediction['NEGATIVO']:\n",
    "        final_predictions.append('1')\n",
    "    else:\n",
    "        final_predictions.append('0')\n",
    "final_predictions = np.array(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_ans = test_base['sentiment'].values\n",
    "real_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(real_ans, final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(real_ans, final_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='d', cmap='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
